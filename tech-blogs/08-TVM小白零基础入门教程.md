# TVM å°ç™½é›¶åŸºç¡€å…¥é—¨æ•™ç¨‹

## ğŸ–ï¸ å‰è¨€ï¼šè¿™ç¯‡æ–‡ç« å†™ç»™è°ï¼Ÿ

å¦‚æœä½ ï¼š
- å®Œå…¨æ²¡å¬è¯´è¿‡TVM
- å¯¹AIç¼–è¯‘å™¨ä¸€æ— æ‰€çŸ¥
- åªä¼šPythonï¼Œä¸æ‡‚C++
- æƒ³äº†è§£æ¨¡å‹æ€ä¹ˆåœ¨æ‰‹æœºä¸Šè¿è¡Œå¾—æ›´å¿«
- çœ‹åˆ°TVMæ–‡æ¡£å°±å¤´æ™•

é‚£ä¹ˆè¿™ç¯‡æ–‡ç« å°±æ˜¯ä¸ºä½ å†™çš„ï¼æˆ‘ä¼šç”¨æœ€ç®€å•çš„è¯­è¨€ï¼Œä¸€æ­¥æ­¥å¸¦ä½ å…¥é—¨TVMã€‚

## ğŸƒâ€â™‚ï¸ å…ˆäº†è§£ï¼šAIæ¨¡å‹æ˜¯æ€ä¹ˆè¿è¡Œçš„ï¼Ÿ

### ä¼ ç»Ÿæ–¹å¼ï¼ˆæ…¢ï¼‰
```python
# æ¯”å¦‚ç”¨PyTorchè®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹
import torch
model = torch.load("my_model.pth")

# ç›´æ¥æ¨ç† - åœ¨CPUä¸Šè¿è¡Œå¾ˆæ…¢
result = model(input_data)
```

### é—®é¢˜æ‰€åœ¨
- **å¤ªæ…¢**ï¼šåœ¨æ‰‹æœºä¸Šå¯èƒ½è¦å‡ ç§’æ‰èƒ½å¤„ç†ä¸€å¼ å›¾ç‰‡
- **å¤ªè€—ç”µ**ï¼šå¤§é‡è®¡ç®—æ¶ˆè€—ç”µæ± 
- **å¤ªå å†…å­˜**ï¼šæ¨¡å‹æ–‡ä»¶å¤§ï¼Œè¿è¡Œå†…å­˜ä¹Ÿå¤§

### è§£å†³æ–¹æ¡ˆï¼šç¼–è¯‘ä¼˜åŒ–
```
ä½ çš„AIæ¨¡å‹ (åƒPythonä»£ç )
    â†“
TVMç¼–è¯‘å™¨ (åƒç¿»è¯‘å®˜)
    â†“
ä¼˜åŒ–åçš„ä»£ç  (åƒæœºå™¨è¯­è¨€)
    â†“
åœ¨æ‰‹æœº/æœåŠ¡å™¨ä¸Šé«˜é€Ÿè¿è¡Œ
```

## ğŸ¤” TVMåˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ

### å®˜æ–¹å®šä¹‰ï¼ˆç®€å•ç†è§£ï¼‰
TVM = **T**ensor **V**irtual **M**achineï¼ˆå¼ é‡è™šæ‹Ÿæœºï¼‰

### æ›´é€šä¿—çš„è§£é‡Š
TVMå°±åƒæ˜¯**AIæ¨¡å‹çš„"ç¿»è¯‘å®˜" + "ä¼˜åŒ–å¸ˆ"**ï¼š

1. **ç¿»è¯‘å®˜**ï¼šæŠŠå„ç§AIæ¡†æ¶çš„æ¨¡å‹"ç¿»è¯‘"æˆç¡¬ä»¶èƒ½æ‡‚çš„è¯­è¨€
2. **ä¼˜åŒ–å¸ˆ**ï¼šæ‰¾å‡ºè®©æ¨¡å‹è¿è¡Œæœ€å¿«çš„æœ€ä½³æ–¹å¼

### æ”¯æŒçš„æ¡†æ¶ï¼ˆè¾“å…¥ï¼‰
- âœ… PyTorch
- âœ… TensorFlow
- âœ… Keras
- âœ… MXNet
- âœ… ... è¿˜æœ‰æ›´å¤š

### æ”¯æŒçš„ç¡¬ä»¶ï¼ˆè¾“å‡ºï¼‰
- âœ… CPU (Intel, AMD, ARM)
- âœ… GPU (NVIDIA, AMD, Intel)
- âœ… æ‰‹æœºèŠ¯ç‰‡ (é«˜é€šã€åä¸ºã€è‹¹æœ)
- âœ… åµŒå…¥å¼è®¾å¤‡
- âœ… ... å‡ ä¹æ‰€æœ‰ä¸»æµç¡¬ä»¶

## ğŸ¯ TVMèƒ½åšä»€ä¹ˆï¼Ÿï¼ˆå®é™…åº”ç”¨åœºæ™¯ï¼‰

### åœºæ™¯1ï¼šæ‰‹æœºä¸Šçš„AIåº”ç”¨
```python
# ä½ çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å¯èƒ½åœ¨æœåŠ¡å™¨ä¸Šè®­ç»ƒæ•ˆæœå¾ˆå¥½
# ä½†ç›´æ¥æ”¾åˆ°æ‰‹æœºä¸Šè¿è¡Œå°±ä¼šå¾ˆæ…¢

# TVMå¯ä»¥å¸®ä½ ï¼š
1. æŠŠæ¨¡å‹"å‹ç¼©"å¾—æ›´å°
2. è®©æ¨¡å‹åœ¨æ‰‹æœºä¸Šè¿è¡Œæ›´å¿«
3. æ›´çœç”µï¼Œä¸å‘çƒ­

# å°±åƒï¼šæŠŠ"è±ªåè·‘è½¦"æ”¹è£…æˆ"èŠ‚èƒ½æ±½è½¦"
```

### åœºæ™¯2ï¼šæœåŠ¡å™¨ç«¯é«˜æ€§èƒ½æ¨ç†
```python
# æ¯æ¬¡æ¨ç†èŠ‚çº¦1æ¯«ç§’ï¼Œä¸€å¤©å°±èƒ½èŠ‚çœå¾ˆå¤šæ—¶é—´
# TVMå¯ä»¥è®©ä½ çš„AIæœåŠ¡å“åº”æ›´å¿«
```

### åœºæ™¯3ï¼šè¾¹ç¼˜è®¾å¤‡
```python
# æ¯”å¦‚æ™ºèƒ½æ‘„åƒå¤´ã€æ™ºèƒ½éŸ³ç®±ã€è‡ªåŠ¨é©¾é©¶æ±½è½¦
# è¿™äº›è®¾å¤‡è®¡ç®—èƒ½åŠ›æœ‰é™ï¼ŒTVMèƒ½è®©AIæ¨¡å‹åœ¨æœ‰é™èµ„æºä¸‹è¿è¡Œ
```

## ğŸ”§ TVMå·¥ä½œåŸç†ï¼ˆè¶…çº§ç®€åŒ–ç‰ˆï¼‰

### ç¬¬1æ­¥ï¼šæ¨¡å‹å¯¼å…¥
```python
import tvm
from tvm import relay
from torchvision import models

# å¯¼å…¥PyTorchæ¨¡å‹
model = models.resnet18(pretrained=True)
model.eval()

# è½¬æ¢ä¸ºTVMæ ¼å¼
input_name = "input0"
input_shape = (1, 3, 224, 224)
input_data = torch.randn(input_shape)

traced_model = torch.jit.trace(model, input_data)
mod, params = relay.frontend.from_pytorch(traced_model, [(input_name, input_shape)])
```

### ç¬¬2æ­¥ï¼šç¼–è¯‘ä¼˜åŒ–
```python
# å®šä¹‰ç›®æ ‡ç¡¬ä»¶
target = tvm.target.Target("llvm")  # CPUç›®æ ‡
# target = tvm.target.Target("cuda")  # GPUç›®æ ‡
# target = tvm.target.Target("llvm -mcpu=cortex-m4")  # åµŒå…¥å¼CPU

# ç¼–è¯‘
with tvm.transform.PassContext(opt_level=3):
    lib = relay.build(mod, target=target, params=params)
```

### ç¬¬3æ­¥ï¼šä¿å­˜å’Œè¿è¡Œ
```python
# ä¿å­˜ç¼–è¯‘åçš„æ¨¡å‹
lib.export_library("resnet18_compiled.so")

# è¿è¡Œ
dev = tvm.cpu(0)
module = tvm.contrib.graph_executor.GraphModule(lib["default"](dev))

# å‡†å¤‡è¾“å…¥æ•°æ®
input_data = tvm.nd.array(np.random.randn(*input_shape).astype("float32"))
module.set_input(input_name, input_data)

# è¿è¡Œæ¨ç†
module.run()
output = module.get_output(0).numpy()
```

## ğŸ“Š TVM vs åŸå§‹æ¡†æ¶ï¼šæ€§èƒ½å¯¹æ¯”

### ç®€å•æ€§èƒ½æµ‹è¯•
```python
import time
import numpy as np

# åˆ›å»ºæµ‹è¯•æ•°æ®
input_data = np.random.randn(1, 3, 224, 224).astype("float32")

# 1. PyTorchæ¨ç†æ—¶é—´
import torch
torch_input = torch.from_numpy(input_data)

start_time = time.time()
with torch.no_grad():
    pytorch_output = model(torch_input)
pytorch_time = time.time() - start_time

# 2. TVMæ¨ç†æ—¶é—´
tvm_input = tvm.nd.array(input_data)
module.set_input("input0", tvm_input)

start_time = time.time()
module.run()
tvm_output = module.get_output(0).numpy()
tvm_time = time.time() - start_time

print(f"PyTorchæ—¶é—´: {pytorch_time:.4f}ç§’")
print(f"TVMæ—¶é—´: {tvm_time:.4f}ç§’")
print(f"åŠ é€Ÿæ¯”: {pytorch_time/tvm_time:.2f}å€")
```

### å…¸å‹ç»“æœ
- **CPUä¸Š**ï¼šé€šå¸¸èƒ½è·å¾—2-10å€åŠ é€Ÿ
- **GPUä¸Š**ï¼šä¼˜åŒ–ç¨‹åº¦å–å†³äºå…·ä½“æ¨¡å‹
- **æ‰‹æœºä¸Š**ï¼šæ˜¾è‘—æ”¹å–„æ€§èƒ½å’ŒåŠŸè€—

## ğŸ§  TVMçš„æ ¸å¿ƒæ¦‚å¿µï¼ˆå°ç™½å‹å¥½ç‰ˆï¼‰

### 1. ä¸­é—´è¡¨ç¤º (IR)
```python
# ä½ å†™çš„Pythonä»£ç 
def add_matrices(A, B):
    return A + B

# TVMçœ‹åˆ°çš„ä¸­é—´è¡¨ç¤ºï¼ˆç®€åŒ–ç‰ˆï¼‰
"""
%0 = tensor(A)           # è¾“å…¥A
%1 = tensor(B)           # è¾“å…¥B
%2 = add(%0, %1)         # æ‰§è¡ŒåŠ æ³•
return %2                # è¿”å›ç»“æœ
"""
```

### 2. è°ƒåº¦ (Scheduling)
```python
# å°±åƒå®‰æ’å·¥ä½œçš„é¡ºåº

# åŸå§‹æ–¹å¼ï¼šä¸€ä¸ªä¸€ä¸ªç®—
for i in range(1000):
    for j in range(1000):
        result[i,j] = A[i,j] + B[i,j]

# TVMè°ƒåº¦åï¼šå¹¶è¡Œè®¡ç®—ï¼ˆå¦‚æœæœ‰å¤šä¸ªCPUæ ¸å¿ƒï¼‰
for i in range(1000):  # å¤–å±‚å¹¶è¡Œ
    for j in range(1000):
        result[i,j] = A[i,j] + B[i,j]
```

### 3. ç›®æ ‡ä¼˜åŒ– (Target Optimization)
```python
# ä¸åŒç¡¬ä»¶ï¼Œä¸åŒä¼˜åŒ–ç­–ç•¥

# CPUä¼˜åŒ–
target_cpu = "llvm"

# GPUä¼˜åŒ–
target_gpu = "cuda"

# æ‰‹æœºä¼˜åŒ–
target_phone = "llvm -mcpu=cortex-a76"

# TVMä¼šæ ¹æ®ç›®æ ‡ç¡¬ä»¶è‡ªåŠ¨é€‰æ‹©æœ€ä½³ä¼˜åŒ–ç­–ç•¥
```

## ğŸš€ è®©TVMè¿è¡Œèµ·æ¥çš„å®Œæ•´ä¾‹å­

### å®‰è£…TVM
```bash
# æ–¹æ³•1ï¼šä½¿ç”¨condaï¼ˆæ¨èæ–°æ‰‹ï¼‰
conda install -c ml-forge tvm

# æ–¹æ³•2ï¼šä½¿ç”¨pip
pip install apache-tvm

# æ–¹æ³•3ï¼šä»æºç ç¼–è¯‘ï¼ˆé€‚åˆé«˜çº§ç”¨æˆ·ï¼‰
git clone https://github.com/apache/tvm.git
cd tvm
mkdir build
cp cmake/config.cmake build
cd build
cmake ..
make -j8
```

### ç¬¬ä¸€ä¸ªTVMç¨‹åºï¼šçŸ©é˜µåŠ æ³•
```python
import tvm
from tvm import te
import numpy as np

# 1. å®šä¹‰è®¡ç®—
n = 1024
A = te.placeholder((n, n), name='A')
B = te.placeholder((n, n), name='B')

# è®¡ç®—C = A + B
C = te.compute((n, n), lambda i, j: A[i, j] + B[i, j], name='C')

# 2. åˆ›å»ºè°ƒåº¦
s = te.create_schedule(C.op)

# 3. åº”ç”¨ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
s[C].parallel(C.op.axis[0])  # å¹¶è¡ŒåŒ–å¤–å±‚å¾ªç¯

# 4. ç¼–è¯‘
target = "llvm"  # CPUç›®æ ‡
f = tvm.build(s, [A, B, C], target)

# 5. è¿è¡Œ
dev = tvm.cpu(0)
a = tvm.nd.array(np.random.randn(n, n).astype("float32"), dev)
b = tvm.nd.array(np.random.randn(n, n).astype("float32"), dev)
c = tvm.nd.array(np.zeros((n, n), dtype="float32"), dev)

# æ‰§è¡Œè®¡ç®—
f(a, b, c)

# éªŒè¯ç»“æœ
expected = a.asnumpy() + b.asnumpy()
print("è®¡ç®—æ­£ç¡®å—?", np.allclose(c.asnumpy(), expected, atol=1e-6))
```

## ğŸ® å®é™…é¡¹ç›®ï¼šä¼˜åŒ–ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ

### é¡¹ç›®ç›®æ ‡
æŠŠä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œç”¨TVMä¼˜åŒ–ï¼Œçœ‹çœ‹æ€§èƒ½æå‡

### æ­¥éª¤1ï¼šå®šä¹‰æ¨¡å‹
```python
import torch
import torch.nn as nn

# ç®€å•çš„ä¸¤å±‚ç¥ç»ç½‘ç»œ
class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 10)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# åˆ›å»ºæ¨¡å‹
model = SimpleNet()
model.eval()
```

### æ­¥éª¤2ï¼šè½¬æ¢ä¸ºTVM
```python
from tvm import relay
import numpy as np

# å‡†å¤‡è¾“å…¥
input_name = "data"
input_shape = (1, 1, 28, 28)  # MNISTå›¾åƒå¤§å°
input_data = torch.randn(input_shape)

# è½¬æ¢æ¨¡å‹
traced_model = torch.jit.trace(model, input_data)
mod, params = relay.frontend.from_pytorch(traced_model, [(input_name, input_shape)])
```

### æ­¥éª¤3ï¼šç¼–è¯‘å’Œä¼˜åŒ–
```python
# å®šä¹‰ç›®æ ‡
target = tvm.target.Target("llvm")

# ç¼–è¯‘
with tvm.transform.PassContext(opt_level=3):
    lib = relay.build(mod, target=target, params=params)

# ä¿å­˜æ¨¡å‹
lib.export_library("simple_net_compiled.so")
```

### æ­¥éª¤4ï¼šæ€§èƒ½æµ‹è¯•
```python
import time

# åˆ›å»ºæµ‹è¯•æ•°æ®
test_data = np.random.randn(*input_shape).astype("float32")

# TVMæ¨ç†
dev = tvm.cpu(0)
module = tvm.contrib.graph_executor.GraphModule(lib["default"](dev))

# é¢„çƒ­
module.set_input("data", test_data)
for _ in range(10):
    module.run()

# æ€§èƒ½æµ‹è¯•
start_time = time.time()
for _ in range(100):
    module.run()
tvm_time = (time.time() - start_time) / 100

print(f"TVMå¹³å‡æ¨ç†æ—¶é—´: {tvm_time:.6f}ç§’")
```

## ğŸ” å¸¸ç”¨TVMå·¥å…·å’Œè°ƒè¯•æŠ€å·§

### 1. æ‰“å°ä¸­é—´è¡¨ç¤º
```python
# æŸ¥çœ‹ä¼˜åŒ–å‰çš„IR
print("ä¼˜åŒ–å‰:")
print(mod)

# æŸ¥çœ‹ä¼˜åŒ–åçš„IR
with tvm.transform.PassContext(opt_level=3):
    mod_opt = relay.optimize(mod, target=target, params=params)
print("ä¼˜åŒ–å:")
print(mod_opt)
```

### 2. æ€§èƒ½åˆ†æ
```python
# TVMå†…ç½®çš„æ€§èƒ½åˆ†æå™¨
from tvm.contrib.debugger import debug_executor

debug = debug_executor.create(mod, lib, dev)
debug.run(input_data)
debug_output = debug.get_output()

print("è¾“å‡ºå½¢çŠ¶:", debug_output.shape)
print("è¾“å‡ºç±»å‹:", debug_output.dtype)
```

### 3. å†…å­˜åˆ†æ
```python
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
def check_memory_usage():
    import psutil
    import os

    process = psutil.Process(os.getpid())
    print(f"å†…å­˜ä½¿ç”¨: {process.memory_info().rss / 1024 / 1024:.2f} MB")

check_memory_usage()
```

## â“ å¸¸è§é—®é¢˜è§£ç­”

### Q1: TVMå­¦èµ·æ¥éš¾å—ï¼Ÿ
**A**:
- **åŸºç¡€ä½¿ç”¨**ï¼šä¸éš¾ï¼Œæœ‰PythonåŸºç¡€å°±èƒ½å¼€å§‹
- **æ·±åº¦ä¼˜åŒ–**ï¼šéœ€è¦ä¸€äº›æ—¶é—´å’Œå®è·µ
- **å®Œå…¨æŒæ¡**ï¼šéœ€è¦ç†è§£ç¼–è¯‘å™¨åŸç†

**å»ºè®®**ï¼šä»ç®€å•ä¾‹å­å¼€å§‹ï¼Œé€æ­¥æ·±å…¥

### Q2: æˆ‘éœ€è¦å­¦C++å—ï¼Ÿ
**A**:
- **åªä½¿ç”¨TVM**ï¼šä¸éœ€è¦ï¼ŒPythonå°±å¤Ÿç”¨
- **æ‰©å±•TVMåŠŸèƒ½**ï¼šéœ€è¦C++
- **è´¡çŒ®TVMé¡¹ç›®**ï¼šå¼ºçƒˆå»ºè®®å­¦C++

### Q3: TVMå’Œå…¶ä»–æ¡†æ¶å¯¹æ¯”ï¼Ÿ
**A**:
- **TVM**ï¼šåŠŸèƒ½å…¨é¢ï¼Œå­¦æœ¯ç ”ç©¶å¤šï¼Œç¤¾åŒºæ´»è·ƒ
- **TensorRT**ï¼šNVIDIAä¸“ç”¨ï¼Œæ€§èƒ½å¾ˆå¥½
- **ONNX Runtime**ï¼šç®€å•æ˜“ç”¨ï¼Œå¾®è½¯ç»´æŠ¤
- **OpenVINO**ï¼šIntelä¸“ç”¨

### Q4: ä»€ä¹ˆæ—¶å€™ç”¨TVMï¼Ÿ
**A**:
- âœ… éœ€è¦è·¨å¹³å°éƒ¨ç½²
- âœ… è¿½æ±‚æè‡´æ€§èƒ½
- âœ… æƒ³è¦æ·±å…¥äº†è§£AIç¼–è¯‘
- âŒ åªæ˜¯å¿«é€Ÿå®éªŒï¼Œç”¨åŸæ¡†æ¶å°±å¤Ÿäº†

## ğŸ¯ å°ç™½å­¦ä¹ è·¯çº¿

### ç¬¬1å‘¨ï¼šåŸºç¡€æ¦‚å¿µ
- ç†è§£ä»€ä¹ˆæ˜¯AIç¼–è¯‘å™¨
- å®‰è£…TVMç¯å¢ƒ
- è¿è¡Œç¬¬ä¸€ä¸ªä¾‹å­

### ç¬¬2å‘¨ï¼šåŸºæœ¬ä½¿ç”¨
- ç†Ÿæ‚‰æ¨¡å‹å¯¼å…¥æµç¨‹
- å°è¯•ä¸åŒç›®æ ‡ç¼–è¯‘
- ç®€å•æ€§èƒ½æµ‹è¯•

### ç¬¬3å‘¨ï¼šä¼˜åŒ–æŠ€æœ¯
- äº†è§£TIRæ¦‚å¿µ
- å°è¯•æ‰‹åŠ¨ä¼˜åŒ–
- å­¦ä¹ è°ƒåº¦æŠ€å·§

### ç¬¬4å‘¨ï¼šå®æˆ˜é¡¹ç›®
- å®Œæ•´çš„æ¨¡å‹ä¼˜åŒ–æµç¨‹
- æ€§èƒ½å¯¹æ¯”åˆ†æ
- éƒ¨ç½²åˆ°å®é™…è®¾å¤‡

## ğŸ‰ æ€»ç»“

é€šè¿‡è¿™ç¯‡æ–‡ç« ï¼Œä½ åº”è¯¥å·²ç»äº†è§£äº†ï¼š

1. **TVMæ˜¯ä»€ä¹ˆ**ï¼šAIæ¨¡å‹çš„ç¿»è¯‘å®˜å’Œä¼˜åŒ–å¸ˆ
2. **ä¸ºä»€ä¹ˆéœ€è¦TVM**ï¼šè®©AIæ¨¡å‹è¿è¡Œæ›´å¿«ã€æ›´çœç”µ
3. **æ€ä¹ˆç”¨TVM**ï¼šä»å®‰è£…åˆ°è¿è¡Œçš„å®Œæ•´æµç¨‹
4. **èƒ½åšä»€ä¹ˆ**ï¼šæ€§èƒ½ä¼˜åŒ–ã€è·¨å¹³å°éƒ¨ç½²ç­‰

### ä¸‹ä¸€æ­¥å»ºè®®
1. **åŠ¨æ‰‹å®è·µ**ï¼šè¿è¡Œæ–‡ç« ä¸­çš„ä»£ç ä¾‹å­
2. **å°è¯•è‡ªå·±çš„æ¨¡å‹**ï¼šæŠŠè‡ªå·±è®­ç»ƒçš„æ¨¡å‹ç”¨TVMä¼˜åŒ–
3. **æ·±å…¥å­¦ä¹ **ï¼šé˜…è¯»TVMå®˜æ–¹æ–‡æ¡£
4. **åŠ å…¥ç¤¾åŒº**ï¼šå‚ä¸TVMæŠ€æœ¯è®¨è®º

è®°ä½ï¼š**å­¦ä¹ ç¼–ç¨‹æœ€å¥½çš„æ–¹å¼å°±æ˜¯å†™ä»£ç ï¼** ä¸è¦æ€•çŠ¯é”™ï¼Œæ¯ä¸ªé”™è¯¯éƒ½æ˜¯å­¦ä¹ çš„æœºä¼šã€‚

---

**å‚è€ƒèµ„æ–™ï¼š**
- [TVMå®˜æ–¹æ–‡æ¡£](https://tvm.apache.org/docs/)
- [TVMæ•™ç¨‹](https://tvm.apache.org/docs/tutorial/index.html)
- [TVM GitHub](https://github.com/apache/tvm)

**å­¦ä¹ TVMï¼Œå¼€å¯AIç¼–è¯‘å™¨çš„å¥‡å¦™æ—…ç¨‹ï¼** ğŸš€